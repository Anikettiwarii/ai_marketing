{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d41c03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"<html><body><h1>Hello, World!</h1><p>This is a paragraph.</p></body></html>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5eda3b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def striphtml(data):\n",
    "    p = re.compile(r'<.*?>')\n",
    "    return p.sub('',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e441862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, World!This is a paragraph.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "striphtml(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f465614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \" <html> <body> <h1>My First Heading</h1> <p>My first paragraph.</p> </body> </html>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "995d1f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' <html> <body> <h1>My First Heading</h1> <p>My first paragraph.</p> </body> </html>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb53776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def striphtml(data):\n",
    "    p = re.compile('<.*?>')\n",
    "    return p.sub('',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8e88a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   My First Heading My first paragraph.  '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "striphtml(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f53b49dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.18.0.post0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: nltk>=3.8 in /opt/anaconda3/lib/python3.11/site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.11/site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.11/site-packages (from nltk>=3.8->textblob) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.11/site-packages (from nltk>=3.8->textblob) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (from nltk>=3.8->textblob) (4.65.0)\n",
      "Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.3/626.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: textblob\n",
      "Successfully installed textblob-0.18.0.post0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a744523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_text = 'ceertain conditionas duriing seveal ggenerations aree moodified in the saame manner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82adfe4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"certain conditions during several generations are modified in the same manner\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "textblb = TextBlob(incorrect_text)\n",
    "textblb.correct()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df0af040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.11/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.11/site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (from nltk) (4.65.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9e87a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem Ipsum is simply dummy text of the printing and typesetting industry.',\n",
       " 'Lorem Ipsum has been the industry standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book.',\n",
       " 'It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged.',\n",
       " 'It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = ['Lorem Ipsum is simply dummy text of the printing and typesetting industry.',\n",
    " 'Lorem Ipsum has been the industry standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book.',\n",
    " \"It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged.\",\n",
    " 'It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.']\n",
    "\n",
    "dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b4a6c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/dhruviii/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16dc16e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lorem Ipsum is simply dummy text of the printing and typesetting industry.', 'Lorem Ipsum has been the industry standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book.', 'It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged.', 'It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.']\n",
      "['Lorem', 'Ipsum', 'is', 'simply', 'dummy', 'text', 'of', 'the', 'printing', 'and', 'typesetting', 'industry', '.']\n",
      "['Lorem', 'Ipsum', 'has', 'been', 'the', 'industry', 'standard', 'dummy', 'text', 'ever', 'since', 'the', '1500s', ',', 'when', 'an', 'unknown', 'printer', 'took', 'a', 'galley', 'of', 'type', 'and', 'scrambled', 'it', 'to', 'make', 'a', 'type', 'specimen', 'book', '.']\n",
      "['It', 'has', 'survived', 'not', 'only', 'five', 'centuries', ',', 'but', 'also', 'the', 'leap', 'into', 'electronic', 'typesetting', ',', 'remaining', 'essentially', 'unchanged', '.']\n",
      "['It', 'was', 'popularised', 'in', 'the', '1960s', 'with', 'the', 'release', 'of', 'Letraset', 'sheets', 'containing', 'Lorem', 'Ipsum', 'passages', ',', 'and', 'more', 'recently', 'with', 'desktop', 'publishing', 'software', 'like', 'Aldus', 'PageMaker', 'including', 'versions', 'of', 'Lorem', 'Ipsum', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/dhruviii/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# Download the 'punkt' tokenizer model\n",
    "nltk.download('punkt')\n",
    "\n",
    "dummy = [\n",
    "    'Lorem Ipsum is simply dummy text of the printing and typesetting industry.',\n",
    "    'Lorem Ipsum has been the industry standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book.',\n",
    "    \"It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged.\",\n",
    "    'It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.'\n",
    "]\n",
    "\n",
    "# Since `dummy` is a list of sentences, we should join them into a single string for `sent_tokenize`\n",
    "text = ' '.join(dummy)\n",
    "\n",
    "sents = sent_tokenize(text)\n",
    "print(sents)\n",
    "\n",
    "# Tokenize each sentence\n",
    "for sent in sents:\n",
    "    print(word_tokenize(sent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b274fb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = ['Lorem Ipsum is simply dummy text of the printing and typesetting industry.',\n",
    " 'Lorem Ipsum has been the industry standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book.',\n",
    " \"It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged.\",\n",
    " 'It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "614f9819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lorem Ipsum is simply dummy text of the printing and typesetting industry.', 'Lorem Ipsum has been the industry standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book.', 'It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged.', 'It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.']\n",
      "['Lorem', 'Ipsum', 'is', 'simply', 'dummy', 'text', 'of', 'the', 'printing', 'and', 'typesetting', 'industry', '.']\n",
      "['Lorem', 'Ipsum', 'has', 'been', 'the', 'industry', 'standard', 'dummy', 'text', 'ever', 'since', 'the', '1500s', ',', 'when', 'an', 'unknown', 'printer', 'took', 'a', 'galley', 'of', 'type', 'and', 'scrambled', 'it', 'to', 'make', 'a', 'type', 'specimen', 'book', '.']\n",
      "['It', 'has', 'survived', 'not', 'only', 'five', 'centuries', ',', 'but', 'also', 'the', 'leap', 'into', 'electronic', 'typesetting', ',', 'remaining', 'essentially', 'unchanged', '.']\n",
      "['It', 'was', 'popularised', 'in', 'the', '1960s', 'with', 'the', 'release', 'of', 'Letraset', 'sheets', 'containing', 'Lorem', 'Ipsum', 'passages', ',', 'and', 'more', 'recently', 'with', 'desktop', 'publishing', 'software', 'like', 'Aldus', 'PageMaker', 'including', 'versions', 'of', 'Lorem', 'Ipsum', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/dhruviii/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Download the 'punkt' tokenizer model if not already downloaded\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "dummy = [\n",
    "    'Lorem Ipsum is simply dummy text of the printing and typesetting industry.',\n",
    "    'Lorem Ipsum has been the industry standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book.',\n",
    "    \"It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged.\",\n",
    "    'It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.'\n",
    "]\n",
    "\n",
    "text = ' '.join(dummy)\n",
    "\n",
    "\n",
    "sents = sent_tokenize(text)\n",
    "print(sents)\n",
    "\n",
    "\n",
    "for sent in sents:\n",
    "    print(word_tokenize(sent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a078d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d017902",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
