{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a818b66",
   "metadata": {},
   "source": [
    "### PROGRAM 1: Reading from pdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2272cf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m953.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a64215df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e81b0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfFileReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18b9e814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Sample PDF for Text Extraction\n",
      "Section 1: Introduction\n",
      "Natural Language Processing (NLP) is a field of Artificial Intelligence that focuses on the interaction\n",
      "between computers and humans through natural language. It involves reading, understanding, and\n",
      "deriving meaning from human language.\n",
      "Section 2: Basic Concepts\n",
      "Tokenization: The process of splitting text into individual words or phrases.\n",
      "Stemming: Reducing words to their root forms.\n",
      "Lemmatization: Grouping together different forms of a word to analyze them as a single item.\n",
      "Section 3: Conclusion\n",
      "NLP is a powerful tool that allows machines to understand and respond to human language\n",
      "effectively. Its applications range from sentiment analysis to machine translation.\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "# Creating a PDF file object\n",
    "pdf = open(\"file.pdf\", \"rb\")\n",
    "\n",
    "# Creating a PDF reader object using the new PdfReader\n",
    "pdf_reader = PyPDF2.PdfReader(pdf)\n",
    "\n",
    "# Checking the number of pages in the PDF file\n",
    "print(len(pdf_reader.pages))\n",
    "\n",
    "# Creating a page object\n",
    "page = pdf_reader.pages[0]\n",
    "\n",
    "# Extracting text from the page\n",
    "text = page.extract_text()\n",
    "print(text)\n",
    "\n",
    "# Close the PDF file after processing\n",
    "pdf.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc611338",
   "metadata": {},
   "source": [
    "### PROGRAM 2: Reading from word file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdb1cac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from python-docx) (4.9.3)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /opt/anaconda3/lib/python3.11/site-packages (from python-docx) (4.9.0)\n",
      "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m905.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: python-docx\n",
      "Successfully installed python-docx-1.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e40df6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "from docx import document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6149a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Section 1: Introduction Natural Language Processing (NLP) is a field of Artificial Intelligence that focuses on the interaction between computers and humans through natural language. It involves reading, understanding, and deriving meaning from human language. Section 2: Basic Concepts Tokenization: The process of splitting text into individual words or phrases. Stemming: Reducing words to their root forms. Lemmatization: Grouping together different forms of a word to analyze them as a single item. Section 3: Conclusion NLP is a powerful tool that allows machines to understand and respond to human language effectively. Its applications range from sentiment analysis to machine translation.\n"
     ]
    }
   ],
   "source": [
    "doc = open(\"file.docx\",\"rb\")\n",
    "document = docx.Document(doc)\n",
    "\n",
    "docu = \" \"\n",
    "\n",
    "for para in document.paragraphs:\n",
    "    docu += para.text\n",
    "print(docu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05fed6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_dict = {'nlp': 'natural language processing ', 'ur': 'your', 'wbu': 'what about you', 'gr8': 'great'}\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f509d4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_std(input_text):\n",
    "    words = input_text.split()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        word = re.sub(r'[^\\w\\s]', \"\", word)\n",
    "        if word.lower() in lookup_dict:\n",
    "            word = lookup_dict[word.lower()]\n",
    "            new_words.append(word)\n",
    "            new_text = \" \".join(new_words)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bcf22a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'natural language processing '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_std('nlp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408d45f1",
   "metadata": {},
   "source": [
    "### PROGRAM 3: WORD CLOUD CODE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfea0ed6",
   "metadata": {},
   "source": [
    "## copy lecture 6 codes over here for word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6d7b85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
